{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does BPM correlate with song popularity over time? #\n",
    "A computational essay by Richard Li, Natsuki Sacks, Norah Evans "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "Over the past few years of human existence, *everything* has gotten faster. Instant deliveries, messaging, food, etc. A common critique of the 21st century is that it's built on speed. Our group wondered if that holds true for songs. \n",
    "\n",
    "**Have we begun enjoying faster songs as everything around us accelerates?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology #\n",
    "\n",
    "In order to answer our research question of whether the average tempo of the most popular songs has increased in the modern era, we must accomplish 3 things:\n",
    "\n",
    "1. Find a metric for popularity among songs in a year\n",
    "2. Find the BPM of those songs\n",
    "3. Average the BPM and chart the trends over the course of many years\n",
    "\n",
    "Each of these things occur in 3 files:\n",
    "1. billboard.py\n",
    "2. bpm.py\n",
    "3. visualization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some dependencies for our code to work:\n",
    "from time import sleep\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step One ##\n",
    "We found this [Billboard Top 100](BillboardTop100of.com) website to scrape our data from. The Billboard Top 100 contains the rank, artist, and song for up to the top 100 songs for years 1940 to 2021. Some of the Top Billboards in the 40s contain only 30 to 80 songs, but beggars can't be choosers.\n",
    "\n",
    "The metric for ranking on this website is based off of the Billboard Magazine, which has been keeping track of the music industry for years now.\n",
    "\n",
    "### 1a. Scraping the Data ###\n",
    "To analyze the data's BPM, we first need to scrape it from this website. We chose to scrape our data from the [Billboard Top 100](BillboardTop100of.com), since the APIs we found didn't provide all of the information we needed for free.\n",
    "\n",
    "Each year contained a table made up of the song information for that year. To extract all of the information in that table (rank, artist, song), we used the Python Requests library to grab all of the data for a given year. We then parsed our data using BeautifulSoup, and then extracted all of the important information from that HTML parse by finding all data within a given tag (also by using Beautiful Soup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function we used to grab Billboard data for a given year.\n",
    "def get_data(year):\n",
    "    # Years 1940 and 2020 had different URLs than every other year \n",
    "    if year == (2020):\n",
    "        url = \"http://billboardtop100of.com/billboard-top-100-songs-2020-2/\"\n",
    "    elif year == 1940:\n",
    "        url = \"http://billboardtop100of.com/336-2/\"\n",
    "    else:\n",
    "        url = f\"http://billboardtop100of.com/{year}-2/\"\n",
    "    response = requests.get(url)\n",
    "    data = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't print out all of the data returns from the HTML Request, since it's pretty much a bunch of gibberish with some important information sprinkled in between. \n",
    "\n",
    "To figure out what tag we needed to look for, we went in to the [Billboard Top 100](BillboardTop100of.com) page for the given year and inspected an element that we needed (i.e. \"The Weeknd\"). We did end up doing this for about 15 pages or so, since years 1945 to 2016 had the same body tags, while all remaining years had varying tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# how to make variables global?\n",
    "# check 2013 and 2015 data\n",
    "data = get_data(2014)\n",
    "music_data = data.findAll(\"p\")\n",
    "\n",
    "print(music_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Cleaning the Data ###\n",
    "As we can see, `music_data` contains the information we need, but also contains a bunch of HTML code that we don't need. It also isn't formatted properly; at the end of all this, we want a list of lists that contain three string elements: the rank, artist, and song for all ~100 songs of the year.\n",
    "\n",
    "For the more straightforward years, where each rank, artist, and song were already separated into a list of strings with random newlines or external links in between, the `remove_long_tags` function was used to clean all of that data by calling one line of code.\n",
    "\n",
    "Some years had more convoluted tags, line breaks, external images, etc. stuck in between important information, so those were cleaned using the `remove_long_tags` function in addition to other `.replace` commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of what cleaning a less-messy data set looks like\n",
    "\n",
    "# Removing all p-tags, \"amp;\", \"/n\", and more for 2014\n",
    "clean_data = remove_long_tags(\"<p\", music_data)\n",
    "\n",
    "# Removes all external links (images, additional information)\n",
    "clean_data_more = remove_long_tags(\"<a\", clean_data)\n",
    "\n",
    "# Splits the list of strings into a list of lists, grouping the strings into\n",
    "# lists at intervals of three\n",
    "split_list = split_list_into_three(clean_data_more)\n",
    "\n",
    "print(split_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Loading the Data into the Data Frame \n",
    "`split_list` is then loaded into the data frame using the `import_to_df` function in `billboard_functions.py`. This data frame is 80 columns (one for each year searched for, excluding 2021) by 100 rows (one for every song on the Billboard Top 100 for each year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function used to load the files into the data frame\n",
    "def import_to_df(split_list, year, df):\n",
    "    for i in range(1, len(split_list) + 1):\n",
    "        df.at[i, year] = split_list[i - 1]\n",
    "        \n",
    "    df.to_csv(\"../data/top100.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Two\n",
    "[Spotipy](https://spotipy.readthedocs.io/en/2.19.0/) is a python wrapper for Spotify's API. We use this in order to query spotify for the tempo information corresponding to the songs we found in step one. The end goal of step 2 is to produce a csv that contains the tempo data for all top 100 songs from 1940 to 2021.\n",
    "\n",
    "In order to use it, we have to set up a client :\n",
    "\n",
    "*The YAML config file is here so that we can save the token in a way that isn't accessible to everyone who views the Github repo. It's .gitignored to ensure it cannot be uploaded to the internet.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../config.yaml\",\"r\") as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(\n",
    "    client_id=config[\"SPOTIPY_CLIENT_ID\"], client_secret=config[\"SPOTIPY_CLIENT_SECRET\"])\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Parsing data from billboard.py ###\n",
    "`billboard.py` produced the information we need: a csv file in which every cell is a list of three things: rank, song, artist (`data/top100.csv`). We can now create a dataframe containing that information so that we can easily manipulate it in python. We'll also want to create an empty dataframe that we'll fill out with information after querying Spotify for every song we find in `top100.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of years that you'd like to start and stop querying\n",
    "START_YEAR = 1940\n",
    "END_YEAR = 2019\n",
    "\n",
    "# Open the datafile from billboard scraping\n",
    "song_df = pd.read_csv(\"../data/top100.csv\").set_index(\"index\")\n",
    "\n",
    "# Initialize an empty dataframe where tempo information will be stored\n",
    "tempo_df = pd.DataFrame(index=range(\n",
    "    1, 101), columns=range(START_YEAR, END_YEAR+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Querying Spotify ###\n",
    "Now that we have a Spotify client open with spotipy, we can set up a function that we'll call repeatedly in order to find the information that we desire. Querying spotify for a song's \"audio features\" returns a list of many many things, including energy, danceability, and so on. However, we only care about a single metric: tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_spotify(track, artist):\n",
    "    \"\"\"\n",
    "    Queries Spotify's API for the tempo information corresponding to a track by an artist.\n",
    "\n",
    "    Args:\n",
    "        track (str): the track to find bpm info for\n",
    "        artist (str): the artist of that track\n",
    "\n",
    "    Returns:\n",
    "        audio_features[\"tempo] (int): an integer containing the BPM of that song\n",
    "\n",
    "        OR\n",
    "\n",
    "        ValueError: if no song is found corresponding to the query\n",
    "    \"\"\"\n",
    "    search_query = track + ' ' + artist\n",
    "    search_results = sp.search(q=search_query)\n",
    "    uri = search_results[\"tracks\"][\"items\"][0][\"uri\"]\n",
    "    audio_features = sp.audio_features(uri)[0]\n",
    "    return audio_features[\"tempo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Filling out bpm.csv ###\n",
    "\n",
    "Now, it's as simple as iterating through our top100 dataframe `song_df` and filling it out with the tempo information we get from spotify, dumping the result into our created dataframe `tempo_df`. You'll note that there are a few \"try and except\" clauses in the loop. This is because the data is, as previously mentioned, a little incomplete. Some years don't have all 100 songs, and some of the songs listed can't be found on Spotify. In order to recitfy both of these problems, we catch the exceptions that occur and fill out any problematic cells with `None`. This way, the cell won't influence the average and we'll still have data that is representative of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all of the years of data\n",
    "for i in range(START_YEAR, END_YEAR+1):\n",
    "    print(\"i is now: \", str(i))\n",
    "\n",
    "    # Iterate through all 100 songs for each year\n",
    "    for j in range(1, 101):\n",
    "        print(\"we are now on the\", str(j), \"th song\")\n",
    "\n",
    "        # Each cell is a list, but it's saved as a string right now\n",
    "        # literal_eval will evaluate it as a list\n",
    "        try:\n",
    "            next_entry = literal_eval(song_df[str(i)][j])\n",
    "\n",
    "        # If there is no song in that cell go to next year\n",
    "        except ValueError:\n",
    "            break\n",
    "\n",
    "        # Try to query spotify for BPM info\n",
    "        try:\n",
    "            # The track + artist will be the 2nd and 3rd element of the list in the cell\n",
    "            tempo_df.at[j, i] = query_spotify(next_entry[1], next_entry[2])\n",
    "\n",
    "        # If song isn't found, set the value as NaN so it doesn't mess with the average\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "            tempo_df.at[j, i] = None\n",
    "\n",
    "    # Pause to avoid over-requesting Spotify\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can save this to a csv for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the resulting dataframe to a CSV file that visualization.py can use\n",
    "tempo_df.to_csv(\"../data/bpmFULL.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP THREE ##\n",
    "It was important to visualize all the data in multiple ways in order to find trends. Without comparing each piece of data it would be impossible to gather evidence to suggest correlation between popularity and bpm.\n",
    "\n",
    "Using the CSV file created in section 2, the data was put into three graphs to help visualize any present trends. Using the help of Pandas and Matplotlib we were able to plot the data into two line graphs and one scatter plot. Three function were made to create these graphs: `yearvsbpm()`, `scatterplot()`, and `popularityvsbpm()`. \n",
    "\n",
    "`yearvsbpm` first takes an average of the bpm of every top 100 song in a particular year. Then it graphs the average bpm compared to the year the songs were popular. \n",
    "\n",
    "`scatterplot()` groups together each decade of top 100 songs and assigns them a color. It then plots each song on it's rank compared to it's bpm.\n",
    "\n",
    "`popularityvsbpm()` takes an average of the bpm of every song of a particular rank in every year data is present. It then graphs the average bpm compared to the rank the songs were at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
